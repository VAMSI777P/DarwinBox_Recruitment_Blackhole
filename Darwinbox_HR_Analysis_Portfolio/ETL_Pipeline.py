{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af97505-04c8-4548-90cf-bbf7c82dc54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime, timedelta\n",
    "import getpass \n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "SERVER_NAME = 'VAMSI-777\\SQLEXPRESS' # e.g., 'LOCALHOST' or 'DESKTOP-XYZ\\SQLEXPRESS'\n",
    "DATABASE_NAME = 'Darwinbox_Analytics' \n",
    "USE_WINDOWS_AUTH = True # Set True if using Windows Login\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATA GENERATION ENGINE (The \"Black Hole\" Logic)\n",
    "# ==========================================\n",
    "def generate_data(num_candidates=12000):\n",
    "    print(f\"üöÄ Generating data for {num_candidates} candidates...\")\n",
    "    \n",
    "    START_DATE = datetime(2023, 10, 1)\n",
    "    SOURCES = ['LinkedIn', 'Referral', 'CareerSite', 'Agency', 'Naukri']\n",
    "    ROLES = ['Data Analyst', 'Data Engineer', 'Product Manager']\n",
    "    \n",
    "    # 15% of people get \"Stuck\" in Tech Round (The Problem)\n",
    "    FATE_CHOICES = ['Rejected_Screening', 'Rejected_Tech', 'Hired', 'STUCK_IN_TECH']\n",
    "    FATE_WEIGHTS = [0.50, 0.20, 0.15, 0.15] \n",
    "    \n",
    "    data_rows = []\n",
    "\n",
    "    for i in range(1, num_candidates + 1):\n",
    "        c_id = 1000 + i\n",
    "        # Attributes\n",
    "        name = f\"Candidate_{c_id}\" # Simple names for privacy\n",
    "        source = random.choice(SOURCES)\n",
    "        role = random.choice(ROLES)\n",
    "        fate = random.choices(FATE_CHOICES, weights=FATE_WEIGHTS, k=1)[0]\n",
    "        \n",
    "        # Event History\n",
    "        curr_date = START_DATE + timedelta(days=random.randint(0, 120))\n",
    "        \n",
    "        # STAGE 1: Applied\n",
    "        data_rows.append([c_id, name, source, role, 'Applied', curr_date, 'Completed'])\n",
    "        \n",
    "        # STAGE 2: Screening\n",
    "        curr_date += timedelta(days=random.randint(1, 3))\n",
    "        if fate == 'Rejected_Screening':\n",
    "            data_rows.append([c_id, name, source, role, 'Screening', curr_date, 'Rejected'])\n",
    "            continue\n",
    "        data_rows.append([c_id, name, source, role, 'Screening', curr_date, 'Completed'])\n",
    "\n",
    "        # STAGE 3: Tech Round (The Bottleneck)\n",
    "        curr_date += timedelta(days=random.randint(2, 6))\n",
    "        if fate == 'STUCK_IN_TECH':\n",
    "            data_rows.append([c_id, name, source, role, 'Tech_Round_1', curr_date, 'Started'])\n",
    "            continue # They get stuck here!\n",
    "            \n",
    "        if fate == 'Rejected_Tech':\n",
    "            data_rows.append([c_id, name, source, role, 'Tech_Round_1', curr_date, 'Rejected'])\n",
    "            continue\n",
    "        data_rows.append([c_id, name, source, role, 'Tech_Round_1', curr_date, 'Completed'])\n",
    "\n",
    "        # STAGE 4: Offer (Happy Path)\n",
    "        if fate == 'Hired':\n",
    "            curr_date += timedelta(days=random.randint(5, 10))\n",
    "            data_rows.append([c_id, name, source, role, 'Offer', curr_date, 'Offered'])\n",
    "\n",
    "    # Create Master DataFrame\n",
    "    cols = ['CandidateID', 'Name', 'Source', 'Applied_Role', 'Stage', 'EventDate', 'Status']\n",
    "    return pd.DataFrame(data_rows, columns=cols)\n",
    "\n",
    "# ==========================================\n",
    "# 3. CONNECTION & UPLOAD ENGINE\n",
    "# ==========================================\n",
    "def reset_and_upload(df):\n",
    "    print(\"\\nüîå Connecting to SQL Server...\")\n",
    "    \n",
    "    # Secure Login\n",
    "    if USE_WINDOWS_AUTH:\n",
    "        conn_str = f\"mssql+pyodbc://@{SERVER_NAME}/{DATABASE_NAME}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\"\n",
    "    else:\n",
    "        user = input(\"SQL Username: \")\n",
    "        pwd = getpass.getpass(\"SQL Password: \")\n",
    "        conn_str = f\"mssql+pyodbc://{user}:{pwd}@{SERVER_NAME}/{DATABASE_NAME}?driver=ODBC+Driver+17+for+SQL+Server\"\n",
    "\n",
    "    engine = create_engine(conn_str, fast_executemany=True)\n",
    "\n",
    "    try:\n",
    "        # A. CLEANUP: Drop old tables if they exist\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(\"IF OBJECT_ID('Fact_Application_History', 'U') IS NOT NULL DROP TABLE Fact_Application_History\"))\n",
    "            conn.execute(text(\"IF OBJECT_ID('Dim_Candidates', 'U') IS NOT NULL DROP TABLE Dim_Candidates\"))\n",
    "            conn.execute(text(\"IF OBJECT_ID('Application_Status_History', 'U') IS NOT NULL DROP TABLE Application_Status_History\")) # Drop the old messy one\n",
    "            conn.commit()\n",
    "            print(\"üßπ Old tables deleted (Clean Slate).\")\n",
    "\n",
    "        # B. SPLIT DATA (Normalization)\n",
    "        \n",
    "        # Table 1: Dim_Candidates (Unique IDs only)\n",
    "        df_dim = df[['CandidateID', 'Name', 'Source', 'Applied_Role']].drop_duplicates(subset=['CandidateID'])\n",
    "        df_dim.to_sql('Dim_Candidates', con=engine, index=False, if_exists='replace')\n",
    "        print(f\"‚úÖ Uploaded 'Dim_Candidates' ({len(df_dim)} rows).\")\n",
    "\n",
    "        # Table 2: Fact_History (Events)\n",
    "        df_fact = df[['CandidateID', 'Stage', 'EventDate', 'Status']]\n",
    "        df_fact.to_sql('Fact_Application_History', con=engine, index=False, if_exists='replace')\n",
    "        print(f\"‚úÖ Uploaded 'Fact_Application_History' ({len(df_fact)} rows).\")\n",
    "\n",
    "        print(\"\\nüéâ SUCCESS! Your Professional 2-Table Schema is ready.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Generate\n",
    "    master_df = generate_data()\n",
    "    \n",
    "    # 2. Upload\n",
    "    reset_and_upload(master_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
